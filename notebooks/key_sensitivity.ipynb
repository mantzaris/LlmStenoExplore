{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import List, Tuple, Sequence, Dict, Any\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from itertools import combinations\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from llama_cpp import Llama\n",
    "\n",
    "#   notebook is in LlmStenoExplore/notebooks\n",
    "REPO_ROOT = Path(\"..\").resolve()\n",
    "\n",
    "MODEL_REGISTRY = {\n",
    "    \"phi3_mini_q4\": REPO_ROOT / \"models/phi3/Phi-3-mini-4k-instruct-q4.gguf\",\n",
    "    \"llama3_8b_q4_k_m\": REPO_ROOT / \"models/llama3_8b/Meta-Llama-3-8B-Instruct-Q4_K_M.gguf\",\n",
    "}\n",
    "\n",
    "def load_language_model(model_key: str) -> Llama:\n",
    "    model_path = MODEL_REGISTRY[model_key]\n",
    "    if not model_path.exists():\n",
    "        raise FileNotFoundError(f\"Model file not found: {model_path}\")\n",
    "\n",
    "    maximum_context_tokens = 8192 if \"llama3\" in model_key else 4096\n",
    "\n",
    "    return Llama(\n",
    "        model_path=str(model_path),\n",
    "        n_ctx=maximum_context_tokens,\n",
    "        n_gpu_layers=0,\n",
    "        n_threads=os.cpu_count() or 4,\n",
    "        n_batch=256,\n",
    "        logits_all=True,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "llm = load_language_model(\"llama3_8b_q4_k_m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _make_prefix_ids(prefix: str, model: Llama) -> List[int]:\n",
    "    \"\"\"\n",
    "    Turn a textual prefix (k or k') into initial context token ids.\n",
    "\n",
    "    - If prefix is non-empty: tokenize it and drop the BOS token\n",
    "      (this matches the authors' implementation).\n",
    "    - If prefix is empty: use a single BOS token.\n",
    "\n",
    "    This is used both in encoding (get_token_ranks_like_paper)\n",
    "    and decoding (decode_from_ranks_like_paper), so empty/non-empty\n",
    "    keys are treated consistently everywhere.\n",
    "    \"\"\"\n",
    "    if prefix:\n",
    "        # Tokenize with BOS, then drop BOS (index 0)\n",
    "        token_ids = model.tokenize(prefix.encode(\"utf-8\"), add_bos=True)\n",
    "        return token_ids[1:]\n",
    "    else:\n",
    "        # No textual prefix: start context from BOS\n",
    "        return [model.token_bos()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_token_ranks_like_paper(\n",
    "    text: str,\n",
    "    model: Llama,\n",
    "    prefix: str = \"A text:\",\n",
    ") -> List[int]:\n",
    "    \"\"\"\n",
    "    Token-level rank computation following the paper's recipe:\n",
    "\n",
    "      1. Tokenize e and k' with the LLM tokenizer.\n",
    "      2. For each token e_i, compute its rank among ALL vocab tokens\n",
    "         under p(· | k', e_1,...,e_{i-1}).\n",
    "\n",
    "    This mirrors the authors' get_token_ranks_llama_cpp, but uses\n",
    "    _make_prefix_ids so it behaves sensibly even when prefix == \"\".\n",
    "    \"\"\"\n",
    "    # Initial context tokens from k' (or BOS if prefix == \"\")\n",
    "    prefix_ids = _make_prefix_ids(prefix, model)\n",
    "\n",
    "    # Ensure text is valid UTF-8 and tokenize with leading space, drop BOS\n",
    "    text = text.encode(\"utf-8\", errors=\"ignore\").decode(\"utf-8\")\n",
    "    text_ids = model.tokenize((\" \" + text).encode(\"utf-8\"), add_bos=True)[1:]\n",
    "\n",
    "    model.reset()\n",
    "    model.eval(prefix_ids)\n",
    "\n",
    "    ranks: List[int] = []\n",
    "\n",
    "    # One rank per token in text_ids\n",
    "    for token_id in text_ids:\n",
    "        # logits for next token given current context\n",
    "        logits = np.array(model.scores[model.n_tokens - 1], dtype=np.float32)\n",
    "\n",
    "        # rank of token_id among all vocab entries (1-based)\n",
    "        sorted_indices = np.argsort(logits)[::-1]\n",
    "        positions = np.where(sorted_indices == token_id)[0]\n",
    "        if positions.size == 0:\n",
    "            raise RuntimeError(f\"Token id {token_id} not found in logits\")\n",
    "        rank = int(positions[0]) + 1\n",
    "        ranks.append(rank)\n",
    "\n",
    "        # extend context with this token\n",
    "        model.eval([token_id])\n",
    "\n",
    "    return ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def decode_from_ranks_like_paper(\n",
    "    prompt: str,\n",
    "    ranks: List[int],\n",
    "    model: Llama,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Token-level decoder matching the paper's scheme:\n",
    "\n",
    "      - Turn prompt k or k' into initial context via _make_prefix_ids.\n",
    "      - For each rank r_i:\n",
    "          * get logits for next token given current context\n",
    "          * pick the r_i-th most probable token\n",
    "          * feed it and append to the sequence\n",
    "      - Detokenize and, if prompt is non-empty, strip it from the front.\n",
    "    \"\"\"\n",
    "    prompt_ids = _make_prefix_ids(prompt, model)\n",
    "\n",
    "    model.reset()\n",
    "    model.eval(prompt_ids)\n",
    "\n",
    "    generated_ids = list(prompt_ids)\n",
    "\n",
    "    for rank in ranks:\n",
    "        logits = np.array(model.scores[model.n_tokens - 1], dtype=np.float32)\n",
    "\n",
    "        sorted_indices = np.argsort(logits)[::-1]\n",
    "        if rank < 1 or rank > len(sorted_indices):\n",
    "            raise ValueError(\n",
    "                f\"Rank {rank} out of range for vocabulary size {len(sorted_indices)}\"\n",
    "            )\n",
    "\n",
    "        next_token_id = int(sorted_indices[rank - 1])\n",
    "        generated_ids.append(next_token_id)\n",
    "\n",
    "        model.eval([next_token_id])\n",
    "\n",
    "    decoded_bytes = model.detokenize(generated_ids)\n",
    "    decoded_text = decoded_bytes.decode(\"utf-8\", errors=\"ignore\")\n",
    "\n",
    "    # If we had a textual prompt, strip it; for empty prompt we only had BOS,\n",
    "    # which normally does not render as visible text.\n",
    "    if prompt and decoded_text.startswith(prompt):\n",
    "        decoded_text = decoded_text[len(prompt):].lstrip()\n",
    "\n",
    "    return decoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def hide_text_token_level(\n",
    "    secret_text: str,\n",
    "    secret_prefix: str,\n",
    "    secret_key: str,\n",
    "    model: Llama = llm,\n",
    ") -> Tuple[str, List[int]]:\n",
    "    \"\"\"\n",
    "    Encode pipeline (e -> ranks -> stegotext):\n",
    "\n",
    "      1. Compute ranks for secret_text e after prefix k'.\n",
    "      2. Generate stegotext s from key k by following those ranks.\n",
    "    \"\"\"\n",
    "    ranks = get_token_ranks_like_paper(\n",
    "        text=secret_text,\n",
    "        model=model,\n",
    "        prefix=secret_prefix,\n",
    "    )\n",
    "    stegotext = decode_from_ranks_like_paper(\n",
    "        prompt=secret_key,\n",
    "        ranks=ranks,\n",
    "        model=model,\n",
    "    )\n",
    "    return stegotext, ranks\n",
    "\n",
    "\n",
    "def reveal_text_token_level(\n",
    "    stegotext: str,\n",
    "    secret_prefix: str,\n",
    "    secret_key: str,\n",
    "    model: Llama = llm,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Decode pipeline (s -> ranks -> e):\n",
    "\n",
    "      1. From stegotext s and key k, recover the same ranks.\n",
    "      2. From those ranks and prefix k', reconstruct e.\n",
    "    \"\"\"\n",
    "    recovered_ranks = get_token_ranks_like_paper(\n",
    "        text=stegotext,\n",
    "        model=model,\n",
    "        prefix=secret_key,\n",
    "    )\n",
    "    recovered_text = decode_from_ranks_like_paper(\n",
    "        prompt=secret_prefix,\n",
    "        ranks=recovered_ranks,\n",
    "        model=model,\n",
    "    )\n",
    "    return recovered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_example(\n",
    "    secret_text: str,\n",
    "    secret_prefix: str,\n",
    "    secret_key: str,\n",
    "    model: Llama = llm,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Run one full encode/decode example and log everything consistently:\n",
    "      - secret text\n",
    "      - ranks_e and their length\n",
    "      - stegotext\n",
    "      - token counts for secret and stego (same tokenization as get_token_ranks_like_paper)\n",
    "      - recovered text and equality check\n",
    "    \"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"Secret text e:\")\n",
    "    print(secret_text)\n",
    "    print()\n",
    "\n",
    "    # Encode: e -> (ranks_e) -> stegotext\n",
    "    stegotext, ranks_e = hide_text_token_level(\n",
    "        secret_text=secret_text,\n",
    "        secret_prefix=secret_prefix,\n",
    "        secret_key=secret_key,\n",
    "        model=model,\n",
    "    )\n",
    "\n",
    "    print(\"ranks_e (len = {}):\".format(len(ranks_e)))\n",
    "    print(ranks_e)\n",
    "    print()\n",
    "\n",
    "    print(\"Stegotext s:\")\n",
    "    print(stegotext)\n",
    "    print()\n",
    "\n",
    "    # Same tokenization scheme as get_token_ranks_like_paper\n",
    "    secret_token_ids = model.tokenize((\" \" + secret_text).encode(\"utf-8\"), add_bos=True)[1:]\n",
    "    stego_token_ids  = model.tokenize((\" \" + stegotext).encode(\"utf-8\"), add_bos=True)[1:]\n",
    "\n",
    "    print(\"Secret tokens :\", len(secret_token_ids))\n",
    "    print(\"Stego tokens  :\", len(stego_token_ids))\n",
    "    print(\"len(ranks_e)  :\", len(ranks_e))\n",
    "    print()\n",
    "\n",
    "    # Sanity checks\n",
    "    assert len(secret_token_ids) == len(ranks_e), \"Token count for e does not match len(ranks_e)\"\n",
    "    assert len(stego_token_ids)  == len(ranks_e), \"Token count for s does not match len(ranks_e)\"\n",
    "\n",
    "    # Decode: s -> (ranks) -> e\n",
    "    recovered_text = reveal_text_token_level(\n",
    "        stegotext=stegotext,\n",
    "        secret_prefix=secret_prefix,\n",
    "        secret_key=secret_key,\n",
    "        model=model,\n",
    "    )\n",
    "\n",
    "    print(\"Recovered e:\")\n",
    "    print(recovered_text)\n",
    "    print(\"Recovered == secret_text:\", recovered_text == secret_text)\n",
    "    print(\"-\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Secret text e:\n",
      "THE CURRENT SYSTEM HAS REPEATEDLY FAILED\n",
      "\n",
      "ranks_e (len = 9):\n",
      "[164, 639, 21, 10, 10, 17, 1, 1, 1]\n",
      "\n",
      "Stegotext s:\n",
      "Get sufficient roas tting time. The\n",
      "\n",
      "Secret tokens : 9\n",
      "Stego tokens  : 9\n",
      "len(ranks_e)  : 9\n",
      "\n",
      "Recovered e:\n",
      "THE CURRENT SYSTEM HAS REPEATEDLY FAILED\n",
      "Recovered == secret_text: True\n",
      "------------------------------------------------------------\n",
      "================================================================================\n",
      "Secret text e:\n",
      "The cats like to meow all the time. It is annoying.\n",
      "\n",
      "ranks_e (len = 14):\n",
      "[89803, 14969, 58, 1, 106, 1, 26, 1, 1, 1, 6, 2, 6, 1]\n",
      "\n",
      "Stegotext s:\n",
      "önemlidir Ringvorstellung Schriftgutachten. They have sharp claws\n",
      "\n",
      "Secret tokens : 14\n",
      "Stego tokens  : 14\n",
      "len(ranks_e)  : 14\n",
      "\n",
      "Recovered e:\n",
      "The cats like to meow all the time. It is annoying.\n",
      "Recovered == secret_text: True\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Example 1\n",
    "secret_text_1  = \"THE CURRENT SYSTEM HAS REPEATEDLY FAILED\"\n",
    "secret_prefix_1 = \"A text:\"   # k'\n",
    "secret_key_1    = \"Here it is: the infamous British roasted boar with mint sauce. How to make it perfect.\"\n",
    "\n",
    "run_example(secret_text_1, secret_prefix_1, secret_key_1, model=llm)\n",
    "\n",
    "# Example 2\n",
    "secret_text_2  = \"The cats like to meow all the time. It is annoying.\"\n",
    "secret_prefix_2 = \"\"  # k'\n",
    "secret_key_2    = \"The cat is a feline member just like lions and tigers but much smaller.\"  # k\n",
    "\n",
    "run_example(secret_text_2, secret_prefix_2, secret_key_2, model=llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# goal context\n",
    "\n",
    "conduct research on the 'sensitivity of the key in respect to the stenography text produced, the stego text'. For instance if I have a key eg, 'I like cats' and then another 'I like kittens' to calculate the distance between the keys but then to find the equivalent distance between the stego text to see how much different is the keys are and the mapping to the distance between the stego texts. To do this for a few examples to see how that can work out. so effectively some simple examples of the (d_k, d_s| e) for the same message 'e' and some key and produce the stego text 's' and the distance 'd_k' and 'd_s'.\n",
    "\n",
    "studying here is the map\n",
    "\n",
    "k -> s(k;e)\n",
    "\n",
    "fixed hidden message e, e: how much does changing the key k change the stegotext s? we want empirical pairs\n",
    "\n",
    "(dk(k1,k2), ds(s1,s2)∣e), with  si=s(ki;e)\n",
    "\n",
    "\n",
    "## Distances for keys and stegotexts\n",
    "\n",
    "1. Character level edit distance, Normalized Levenshtein:\n",
    "\n",
    "d_k^{char}(k1,k2) = edit_distance(k1,k2) / max⁡(∣k1∣,∣k2∣,1)\n",
    "\n",
    "says how much you had to literally edit the string.\n",
    "\n",
    "(%pip install python-Levenshtein)\n",
    "\n",
    "2. Token level distance using the same tokenizer as the LLM. Since the protocol is token based, it is natural to look at key distance in token space.\n",
    "\n",
    "Let key_token_ids(k) be the tokenization you already use for prompts (via _make_prefix_ids, but without the BOS heuristic). For two keys with token sequences of possibly different lengths we can use a normalized edit distance in token space.\n",
    "\n",
    "3. Embedding distance\n",
    "\n",
    "In a sentence embedding model (for example a small sentence transformer) we can also measure cosine distance between embeddings of keys:\n",
    "\n",
    "dkemb(k1,k2)=1−cos⁡(emb(k1),emb(k2))\n",
    "\n",
    "says you how far apart the prompts are semantically, not just lexically.\n",
    "\n",
    "4. Token level Hamming distance under the Llama tokenizer.\n",
    "\n",
    "For fixed e, all stegotexts have exactly the same number of tokens (always use the same rank sequence), very clean:\n",
    "\n",
    "dstok(s1,s2)= 1/n \\sum_i^n  \\delta[t_i^(1) \\neq t_i^(2)]\n",
    "\n",
    "where t_i^(j) is the i-th token of stegotext sj\tin the Llama tokenizer and n is the common length. This is a per position token mismatch rate.\n",
    "\n",
    "\n",
    "# plan\n",
    "\n",
    "scatter of key distance vs stego distance\n",
    "\n",
    "Fix a secret text e (something like 10-ish words).\n",
    "Fix a prefix k' (or \"\").\n",
    "Generate many keys of similar length (for example, 5 words).\n",
    "For many key pairs (k1, k2):\n",
    "compute d_k (Levenshtein between keys),\n",
    "compute d_s (Levenshtein between corresponding stegotexts).\n",
    "\n",
    "Plot d_k on the x axis, d_s on the y axis, and save to results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Levenshtein\n",
    "\n",
    "def levenshtein_raw(a: str, b: str) -> int:\n",
    "    \"\"\"\n",
    "    Raw Levenshtein edit distance between two strings.\n",
    "    \"\"\"\n",
    "    return Levenshtein.distance(a, b)\n",
    "\n",
    "\n",
    "def levenshtein_normalized(a: str, b: str) -> float:\n",
    "    \"\"\"\n",
    "    Normalized Levenshtein distance in [0, 1], using max length\n",
    "    as the normalization factor.\n",
    "\n",
    "    0.0 means identical strings, values closer to 1.0 mean more different.\n",
    "    \"\"\"\n",
    "    raw_distance = Levenshtein.distance(a, b)\n",
    "    maximum_length = max(len(a), len(b))\n",
    "    if maximum_length == 0:\n",
    "        return 0.0\n",
    "    return raw_distance / maximum_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_key_and_stego_distances(\n",
    "    secret_text: str,\n",
    "    secret_prefix: str,\n",
    "    secret_key_one: str,\n",
    "    secret_key_two: str,\n",
    "    model: Llama = llm,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    For a fixed secret message e and prefix k',\n",
    "    generate stegotexts for two keys and compute:\n",
    "\n",
    "      - Levenshtein distance between the keys\n",
    "      - Levenshtein distance between the stegotexts\n",
    "\n",
    "    Returns a dictionary with:\n",
    "      - secret_key_one, secret_key_two\n",
    "      - stegotext_one, stegotext_two\n",
    "      - d_k_raw, d_k_norm\n",
    "      - d_s_raw, d_s_norm\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate stegotext for key 1\n",
    "    stegotext_one, _ = hide_text_token_level(\n",
    "        secret_text=secret_text,\n",
    "        secret_prefix=secret_prefix,\n",
    "        secret_key=secret_key_one,\n",
    "        model=model,\n",
    "    )\n",
    "\n",
    "    # Generate stegotext for key 2\n",
    "    stegotext_two, _ = hide_text_token_level(\n",
    "        secret_text=secret_text,\n",
    "        secret_prefix=secret_prefix,\n",
    "        secret_key=secret_key_two,\n",
    "        model=model,\n",
    "    )\n",
    "\n",
    "    # Distances between keys\n",
    "    d_k_raw = levenshtein_raw(secret_key_one, secret_key_two)\n",
    "    d_k_norm = levenshtein_normalized(secret_key_one, secret_key_two)\n",
    "\n",
    "    # Distances between stegotexts\n",
    "    d_s_raw = levenshtein_raw(stegotext_one, stegotext_two)\n",
    "    d_s_norm = levenshtein_normalized(stegotext_one, stegotext_two)\n",
    "\n",
    "    return {\n",
    "        \"secret_key_one\": secret_key_one,\n",
    "        \"secret_key_two\": secret_key_two,\n",
    "        \"stegotext_one\": stegotext_one,\n",
    "        \"stegotext_two\": stegotext_two,\n",
    "        \"d_k_raw\": d_k_raw,\n",
    "        \"d_k_norm\": d_k_norm,\n",
    "        \"d_s_raw\": d_s_raw,\n",
    "        \"d_s_norm\": d_s_norm,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "secret_key_one: I like cats\n",
      "secret_key_two: I like kittens\n",
      "stegotext_one: asticsearch slack-github**\n",
      "\n",
      "I need to find the common interests that are\n",
      "stegotext_two: uyếnTek và các chuyến bay an toàn. I have been following your\n",
      "d_k_raw: 5\n",
      "d_k_norm: 0.35714285714285715\n",
      "d_s_raw: 58\n",
      "d_s_norm: 0.8055555555555556\n"
     ]
    }
   ],
   "source": [
    "secret_text = \"The cats like to meow all the time. It is annoying.\"\n",
    "secret_prefix = \"\"  # or \"A text:\" if you want to use a prefix\n",
    "\n",
    "secret_key_one = \"I like cats\"\n",
    "secret_key_two = \"I like kittens\"\n",
    "\n",
    "result = compute_key_and_stego_distances(\n",
    "    secret_text=secret_text,\n",
    "    secret_prefix=secret_prefix,\n",
    "    secret_key_one=secret_key_one,\n",
    "    secret_key_two=secret_key_two,\n",
    "    model=llm,\n",
    ")\n",
    "\n",
    "for key, value in result.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def precompute_ranks_for_secret(\n",
    "    secret_text: str,\n",
    "    secret_prefix: str,\n",
    "    model: Llama = llm,\n",
    ") -> List[int]:\n",
    "    \"\"\"\n",
    "    Compute the rank sequence for a fixed secret text e and prefix k'\n",
    "    once, to be reused for many different keys k.\n",
    "    \"\"\"\n",
    "    ranks = get_token_ranks_like_paper(\n",
    "        text=secret_text,\n",
    "        model=model,\n",
    "        prefix=secret_prefix,\n",
    "    )\n",
    "    return ranks\n",
    "\n",
    "\n",
    "def generate_stegotext_from_ranks(\n",
    "    ranks: List[int],\n",
    "    secret_key: str,\n",
    "    model: Llama = llm,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Given a rank sequence and a key k, generate the corresponding\n",
    "    stegotext s(k; e) by following those ranks under prompt=k.\n",
    "    \"\"\"\n",
    "    stegotext = decode_from_ranks_like_paper(\n",
    "        prompt=secret_key,\n",
    "        ranks=ranks,\n",
    "        model=model,\n",
    "    )\n",
    "    return stegotext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_KEY_VOCABULARY = [\n",
    "    \"cats\", \"kittens\", \"dogs\", \"puppies\",\n",
    "    \"music\", \"books\", \"coffee\", \"travel\",\n",
    "    \"coding\", \"movies\", \"reading\", \"walking\",\n",
    "    \"running\", \"summer\", \"winter\", \"sunny\",\n",
    "    \"rainy\", \"happy\", \"sad\", \"quiet\",\n",
    "]\n",
    "\n",
    "\n",
    "def generate_random_keys(\n",
    "    number_of_keys: int,\n",
    "    number_of_words: int,\n",
    "    random_seed: int = 0,\n",
    "    vocabulary: Sequence[str] = DEFAULT_KEY_VOCABULARY,\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    Generate simple natural-language-like keys, each with the same\n",
    "    number of words (approx same length). For example:\n",
    "\n",
    "        \"Cats love quiet music.\"\n",
    "    \"\"\"\n",
    "    random_generator = random.Random(random_seed)\n",
    "    keys: List[str] = []\n",
    "\n",
    "    for _ in range(number_of_keys):\n",
    "        words = [random_generator.choice(vocabulary) for _ in range(number_of_words)]\n",
    "        sentence = \" \".join(words).capitalize() + \".\"\n",
    "        keys.append(sentence)\n",
    "\n",
    "    return keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_stegotexts_for_keys(\n",
    "    ranks_for_secret: List[int],\n",
    "    keys: Sequence[str],\n",
    "    model: Llama = llm,\n",
    ") -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    For a fixed secret (encoded by ranks_for_secret), generate stegotext\n",
    "    for each key.\n",
    "    \"\"\"\n",
    "    stegotext_by_key: Dict[str, str] = {}\n",
    "    for key in keys:\n",
    "        stegotext_by_key[key] = generate_stegotext_from_ranks(\n",
    "            ranks=ranks_for_secret,\n",
    "            secret_key=key,\n",
    "            model=model,\n",
    "        )\n",
    "    return stegotext_by_key\n",
    "\n",
    "\n",
    "def compute_pairwise_key_and_stego_distances(\n",
    "    keys: Sequence[str],\n",
    "    stegotext_by_key: Dict[str, str],\n",
    ") -> List[Dict[str, Any]]:\n",
    "    records: List[Dict[str, Any]] = []\n",
    "\n",
    "    for key_one, key_two in combinations(keys, 2):\n",
    "        stego_one = stegotext_by_key[key_one]\n",
    "        stego_two = stegotext_by_key[key_two]\n",
    "\n",
    "        # Distances between keys\n",
    "        d_k_raw = Levenshtein.distance(key_one, key_two)\n",
    "        max_key_length = max(len(key_one), len(key_two), 1)\n",
    "        d_k_norm = d_k_raw / max_key_length\n",
    "\n",
    "        # Distances between stegotexts\n",
    "        d_s_raw = Levenshtein.distance(stego_one, stego_two)\n",
    "        max_stego_length = max(len(stego_one), len(stego_two), 1)\n",
    "        d_s_norm = d_s_raw / max_stego_length\n",
    "\n",
    "        records.append(\n",
    "            {\n",
    "                \"key_one\": key_one,\n",
    "                \"key_two\": key_two,\n",
    "                \"stego_one\": stego_one,\n",
    "                \"stego_two\": stego_two,\n",
    "                \"d_k_raw\": d_k_raw,\n",
    "                \"d_k_norm\": d_k_norm,\n",
    "                \"d_s_raw\": d_s_raw,\n",
    "                \"d_s_norm\": d_s_norm,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_key_vs_stego_levenshtein(\n",
    "    pairwise_records: Sequence[Dict[str, Any]],\n",
    "    use_normalized: bool = True,\n",
    "    output_directory: Path = REPO_ROOT / \"results\",\n",
    "    output_filename: str = \"key_vs_stego_levenshtein_scatter.png\",\n",
    ") -> Path:\n",
    "    \"\"\"\n",
    "    Create a scatter plot with key distance on the x axis and\n",
    "    stegotext distance on the y axis. Save it to output_directory\n",
    "    and return the path.\n",
    "    \"\"\"\n",
    "    output_directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if use_normalized:\n",
    "        x_values = [record[\"d_k_norm\"] for record in pairwise_records]\n",
    "        y_values = [record[\"d_s_norm\"] for record in pairwise_records]\n",
    "        x_label = \"Key Levenshtein distance (normalized)\"\n",
    "        y_label = \"Stegotext Levenshtein distance (normalized)\"\n",
    "    else:\n",
    "        x_values = [record[\"d_k_raw\"] for record in pairwise_records]\n",
    "        y_values = [record[\"d_s_raw\"] for record in pairwise_records]\n",
    "        x_label = \"Key Levenshtein distance (raw)\"\n",
    "        y_label = \"Stegotext Levenshtein distance (raw)\"\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(x_values, y_values, alpha=0.7)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.title(\"Sensitivity of stegotext to key (Levenshtein distance)\")\n",
    "    plt.grid(True)\n",
    "\n",
    "    output_path = output_directory / output_filename\n",
    "    plt.savefig(output_path, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Saved scatter plot to: {output_path}\")\n",
    "    return output_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===\n",
      "key_one: Puppies cats coding travel travel.\n",
      "key_two: Music puppies happy dogs sad.\n",
      "d_k_norm: 0.7941176470588235\n",
      "d_s_norm: 0.9074074074074074\n",
      "===\n",
      "key_one: Puppies cats coding travel travel.\n",
      "key_two: Summer kittens cats dogs coffee.\n",
      "d_k_norm: 0.7647058823529411\n",
      "d_s_norm: 0.8703703703703703\n",
      "===\n",
      "key_one: Puppies cats coding travel travel.\n",
      "key_two: Travel rainy quiet cats happy.\n",
      "d_k_norm: 0.7352941176470589\n",
      "d_s_norm: 0.9464285714285714\n",
      "Saved scatter plot to: /home/meow/Documents/repos/LlmStenoExplore/results/key_vs_stego_levenshtein_scatter.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/meow/Documents/repos/LlmStenoExplore/results/key_vs_stego_levenshtein_scatter.png')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose secret text and prefix (k')\n",
    "secret_text = \"Cats like to meow all the time, it is annoying.\"\n",
    "secret_prefix = \"\"  # or \"A text:\" if you want to condition e\n",
    "\n",
    "# Precompute ranks for the secret once\n",
    "ranks_for_secret = precompute_ranks_for_secret(\n",
    "    secret_text=secret_text,\n",
    "    secret_prefix=secret_prefix,\n",
    "    model=llm,\n",
    ")\n",
    "\n",
    "# Generate a bunch of keys of equal word length\n",
    "number_of_keys = 30\n",
    "number_of_words_per_key = 5\n",
    "\n",
    "keys = generate_random_keys(\n",
    "    number_of_keys=number_of_keys,\n",
    "    number_of_words=number_of_words_per_key,\n",
    "    random_seed=42,\n",
    ")\n",
    "\n",
    "# Stegotexts for each key\n",
    "stegotext_by_key = generate_stegotexts_for_keys(\n",
    "    ranks_for_secret=ranks_for_secret,\n",
    "    keys=keys,\n",
    "    model=llm,\n",
    ")\n",
    "\n",
    "# All pairwise distances (d_k, d_s | e)\n",
    "pairwise_records = compute_pairwise_key_and_stego_distances(\n",
    "    keys=keys,\n",
    "    stegotext_by_key=stegotext_by_key,\n",
    ")\n",
    "\n",
    "# inspect a couple of records\n",
    "for record in pairwise_records[:3]:\n",
    "    print(\"===\")\n",
    "    print(\"key_one:\", record[\"key_one\"])\n",
    "    print(\"key_two:\", record[\"key_two\"])\n",
    "    print(\"d_k_norm:\", record[\"d_k_norm\"])\n",
    "    print(\"d_s_norm:\", record[\"d_s_norm\"])\n",
    "\n",
    "# Plot and save to ../results/\n",
    "plot_key_vs_stego_levenshtein(\n",
    "    pairwise_records=pairwise_records,\n",
    "    use_normalized=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
